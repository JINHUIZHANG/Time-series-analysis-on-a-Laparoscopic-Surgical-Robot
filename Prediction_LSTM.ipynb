{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "main_06March2021.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRQU-2L6aL99"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXM0BVsbc3ki",
        "outputId": "2ef2cbb0-8bc1-42ef-f46c-d33b296e8393"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nk3AAWJaL-D"
      },
      "source": [
        "# load data\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "data = loadmat('/content/drive/MyDrive/6March2021_Prediction/data_norm_160.mat')\n",
        "data = data['data_norm']\n",
        "import os\n",
        "newpath = r'/content/drive/MyDrive/6March2021_Prediction/1step_prediction/' \n",
        "if not os.path.exists(newpath):\n",
        "    os.makedirs(newpath)\n",
        "os.chdir(newpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs0OwmLzaL-E",
        "outputId": "dd302c0a-78ef-48de-f01f-6bdf5772d731"
      },
      "source": [
        "# split data randomly (100,40,20)\n",
        "np.random.seed(0) \n",
        "idx = np.random.permutation(160)\n",
        "print(idx)\n",
        "idx_train = idx[0:100]\n",
        "idx_val = idx[100:140]\n",
        "idx_test = idx[140:]\n",
        "print(idx_train,idx_val,idx_test)\n",
        "data_train = data[idx_train,0]\n",
        "data_val = data[idx_val,0]\n",
        "data_test = data[idx_test,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[110 112 143   7  44 101 122  66  85  86 133  92  26 146 119  62  51  97\n",
            " 128  90  45  56  59   8  37  33 147  61  98 121 135  24  54  80  19  74\n",
            " 131  16  60 120  40  22  63 151 111 145 136  27 118  95  55 109  18 157\n",
            "  30  94  73 107   2 139  83  43  71  10 141 154  96  89 144 132 124  50\n",
            " 100 142  64 106 108  69  49  48  13 158  23 113  20  15  78  52  76   3\n",
            " 159  93   6  68  75  84 129  12 123  14 125  91 137  46  11 102  35  57\n",
            "  41 156  65   1 130 148  42 105   4 138  17 116 104  38   5  53 153 126\n",
            "   0  34  28 114  31 134 127 149  32  29  99  82  79 115 155  72  77  25\n",
            "  81 150 152  39  58 140  88  70  87  36  21   9 103  67 117  47]\n",
            "[110 112 143   7  44 101 122  66  85  86 133  92  26 146 119  62  51  97\n",
            " 128  90  45  56  59   8  37  33 147  61  98 121 135  24  54  80  19  74\n",
            " 131  16  60 120  40  22  63 151 111 145 136  27 118  95  55 109  18 157\n",
            "  30  94  73 107   2 139  83  43  71  10 141 154  96  89 144 132 124  50\n",
            " 100 142  64 106 108  69  49  48  13 158  23 113  20  15  78  52  76   3\n",
            " 159  93   6  68  75  84 129  12 123  14] [125  91 137  46  11 102  35  57  41 156  65   1 130 148  42 105   4 138\n",
            "  17 116 104  38   5  53 153 126   0  34  28 114  31 134 127 149  32  29\n",
            "  99  82  79 115] [155  72  77  25  81 150 152  39  58 140  88  70  87  36  21   9 103  67\n",
            " 117  47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTn_2YtwaL-F"
      },
      "source": [
        "# multivariate multi-step encoder-decoder lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from numpy import shape\n",
        "from numpy import concatenate\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from keras import backend\n",
        "def rmse(y_true, y_pred):\n",
        " return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif out_end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix,0:-1] #label prediction removed\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhJvkZumaL-G"
      },
      "source": [
        "# define input sequence\n",
        "X_train,y_train,X_val,y_val,X_test,y_test = list(),list(),list(),list(),list(),list()\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 30, 1\n",
        "for i in range(data_train.shape[0]):\n",
        "    dataset = data_train[i][:,1:] # drop time series\n",
        "    X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "    X_train.append(X)\n",
        "    y_train.append(y)\n",
        "for i in range(data_val.shape[0]):\n",
        "    dataset = data_val[i][:,1:] # drop time series\n",
        "    X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "    X_val.append(X)\n",
        "    y_val.append(y)\n",
        "for i in range(data_test.shape[0]):\n",
        "    dataset = data_test[i][:,1:] # drop time series\n",
        "    X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "    X_test.append(X)\n",
        "    y_test.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEKGlFj1aL-G",
        "outputId": "9db4318d-52ea-4233-eb77-0ce71917c53d"
      },
      "source": [
        "# push all lists into one 3D array\n",
        "X_train_all,y_train_all,X_val_all,y_val_all,X_test_all,y_test_all = X_train[0],y_train[0],X_val[0],y_val[0],X_test[0],y_test[0]\n",
        "for i in range(1,shape(X_train)[0]):\n",
        "    X_train_all = concatenate((X_train_all,X_train[i]))\n",
        "    y_train_all = concatenate((y_train_all,y_train[i]))\n",
        "for i in range(1,shape(X_val)[0]):\n",
        "    X_val_all = concatenate((X_val_all,X_val[i]))\n",
        "    y_val_all = concatenate((y_val_all,y_val[i]))\n",
        "for i in range(1,shape(X_test)[0]):\n",
        "    X_test_all = concatenate((X_test_all,X_test[i]))\n",
        "    y_test_all = concatenate((y_test_all,y_test[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIhWq8XFaL-G"
      },
      "source": [
        "# y_train_all.reshape(y_train_all.shape[0],y_train_all.shape[1],1)\n",
        "# y_val_all.reshape(y_val_all.shape[0],y_val_all.shape[1],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzMPJcaMaL-H"
      },
      "source": [
        "# save X_train,y_train,X_val,y_val,X_test,y_test\n",
        "from numpy import savez_compressed\n",
        "savez_compressed('X_train_all.npz',X_train_all)\n",
        "savez_compressed('y_train_all.npz',y_train_all)\n",
        "savez_compressed('X_val_all.npz',X_val_all)\n",
        "savez_compressed('y_val_all.npz',y_val_all)\n",
        "savez_compressed('X_test_all.npz',X_test_all)\n",
        "savez_compressed('y_test_all.npz',y_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqnTxYE6aL-H"
      },
      "source": [
        "# from numpy import savez\n",
        "# savez('E:/Study/Jupyter/Forecasting/Data/X_train_all2.npz','X_train_all')\n",
        "# savez('E:/Study/Jupyter/Forecasting/Data/y_train_all2.npz','y_train_all')\n",
        "# savez('E:/Study/Jupyter/Forecasting/Data/X_val_all2.npz','X_val_all')\n",
        "# savez('E:/Study/Jupyter/Forecasting/Data/y_val_all2.npz','y_val_all')\n",
        "# savez('E:/Study/Jupyter/Forecasting/Data/X_test_all2.npz','X_test_all')\n",
        "# savez('E:/Study/Jupyter/Forecasting/Data/y_test_all2.npz','y_test_all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5nubQQzaL-H"
      },
      "source": [
        "# # customize keras.model.fit\n",
        "# class CustomModel(tensorflow.keras.Model):\n",
        "#     def train_step(self, data):\n",
        "#         # Unpack the data. Its structure depends on your model and\n",
        "#         # on what you pass to `fit()`.\n",
        "#         x, y = data\n",
        "\n",
        "#         with tf.GradientTape() as tape:\n",
        "#             y_pred = self(x, training=True)  # Forward pass\n",
        "#             # Compute the loss value\n",
        "#             # (the loss function is configured in `compile()`)\n",
        "#             loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "#         # Compute gradients\n",
        "#         trainable_vars = self.trainable_variables\n",
        "#         gradients = tape.gradient(loss, trainable_vars)\n",
        "#         # Update weights\n",
        "#         self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "#         # Update metrics (includes the metric that tracks the loss)\n",
        "#         self.compiled_metrics.update_state(y, y_pred)\n",
        "#         # Return a dict mapping metric names to current value\n",
        "#         return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_5OoyqYaL-I",
        "outputId": "00447d86-99b1-4542-a5b6-165f99fd1636"
      },
      "source": [
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = 11\n",
        "n_epochs = 100\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(300, activation='relu', input_shape=(n_steps_in, n_features)))\n",
        "model.add(RepeatVector(n_steps_out))\n",
        "model.add(LSTM(300, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(10)))\n",
        "model.compile(optimizer='adam', loss=rmse, metrics=['mae'])\n",
        "# fit and save model\n",
        "model.fit(X_train_all, y_train_all, epochs=n_epochs,validation_data=(X_val_all, y_val_all),verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/100\n",
            "740/740 - 35s - loss: 0.0796 - mae: 0.0645 - val_loss: 0.0519 - val_mae: 0.0410\n",
            "Epoch 2/100\n",
            "740/740 - 33s - loss: 0.0331 - mae: 0.0257 - val_loss: 0.0335 - val_mae: 0.0259\n",
            "Epoch 3/100\n",
            "740/740 - 32s - loss: 0.0242 - mae: 0.0189 - val_loss: 0.0247 - val_mae: 0.0196\n",
            "Epoch 4/100\n",
            "740/740 - 32s - loss: 0.0192 - mae: 0.0151 - val_loss: 0.0173 - val_mae: 0.0136\n",
            "Epoch 5/100\n",
            "740/740 - 32s - loss: 0.0162 - mae: 0.0128 - val_loss: 0.0161 - val_mae: 0.0128\n",
            "Epoch 6/100\n",
            "740/740 - 32s - loss: 0.0143 - mae: 0.0113 - val_loss: 0.0140 - val_mae: 0.0111\n",
            "Epoch 7/100\n",
            "740/740 - 32s - loss: 0.0126 - mae: 0.0099 - val_loss: 0.0137 - val_mae: 0.0111\n",
            "Epoch 8/100\n",
            "740/740 - 32s - loss: 0.0112 - mae: 0.0090 - val_loss: 0.0100 - val_mae: 0.0078\n",
            "Epoch 9/100\n",
            "740/740 - 32s - loss: 0.0103 - mae: 0.0082 - val_loss: 0.0107 - val_mae: 0.0084\n",
            "Epoch 10/100\n",
            "740/740 - 32s - loss: 0.0094 - mae: 0.0075 - val_loss: 0.0110 - val_mae: 0.0086\n",
            "Epoch 11/100\n",
            "740/740 - 32s - loss: 0.0088 - mae: 0.0070 - val_loss: 0.0093 - val_mae: 0.0074\n",
            "Epoch 12/100\n",
            "740/740 - 32s - loss: 0.0081 - mae: 0.0065 - val_loss: 0.0073 - val_mae: 0.0057\n",
            "Epoch 13/100\n",
            "740/740 - 32s - loss: 0.0076 - mae: 0.0061 - val_loss: 0.0091 - val_mae: 0.0071\n",
            "Epoch 14/100\n",
            "740/740 - 32s - loss: 0.0072 - mae: 0.0058 - val_loss: 0.0095 - val_mae: 0.0079\n",
            "Epoch 15/100\n",
            "740/740 - 32s - loss: 0.0072 - mae: 0.0058 - val_loss: 0.0066 - val_mae: 0.0052\n",
            "Epoch 16/100\n",
            "740/740 - 32s - loss: 0.0068 - mae: 0.0055 - val_loss: 0.0069 - val_mae: 0.0054\n",
            "Epoch 17/100\n",
            "740/740 - 31s - loss: 0.0064 - mae: 0.0052 - val_loss: 0.0070 - val_mae: 0.0057\n",
            "Epoch 18/100\n",
            "740/740 - 31s - loss: 0.0063 - mae: 0.0051 - val_loss: 0.0067 - val_mae: 0.0053\n",
            "Epoch 19/100\n",
            "740/740 - 31s - loss: 0.0061 - mae: 0.0049 - val_loss: 0.0070 - val_mae: 0.0057\n",
            "Epoch 20/100\n",
            "740/740 - 32s - loss: 0.0057 - mae: 0.0046 - val_loss: 0.0071 - val_mae: 0.0061\n",
            "Epoch 21/100\n",
            "740/740 - 31s - loss: 0.0057 - mae: 0.0046 - val_loss: 0.0063 - val_mae: 0.0050\n",
            "Epoch 22/100\n",
            "740/740 - 31s - loss: 0.0055 - mae: 0.0044 - val_loss: 0.0057 - val_mae: 0.0047\n",
            "Epoch 23/100\n",
            "740/740 - 31s - loss: 0.0053 - mae: 0.0043 - val_loss: 0.0061 - val_mae: 0.0050\n",
            "Epoch 24/100\n",
            "740/740 - 32s - loss: 0.0053 - mae: 0.0042 - val_loss: 0.0057 - val_mae: 0.0045\n",
            "Epoch 25/100\n",
            "740/740 - 31s - loss: 0.0051 - mae: 0.0041 - val_loss: 0.0057 - val_mae: 0.0047\n",
            "Epoch 26/100\n",
            "740/740 - 32s - loss: 0.0050 - mae: 0.0040 - val_loss: 0.0056 - val_mae: 0.0044\n",
            "Epoch 27/100\n",
            "740/740 - 32s - loss: 0.0048 - mae: 0.0038 - val_loss: 0.0054 - val_mae: 0.0042\n",
            "Epoch 28/100\n",
            "740/740 - 32s - loss: 0.0050 - mae: 0.0041 - val_loss: 0.0051 - val_mae: 0.0040\n",
            "Epoch 29/100\n",
            "740/740 - 31s - loss: 0.0046 - mae: 0.0037 - val_loss: 0.0062 - val_mae: 0.0046\n",
            "Epoch 30/100\n",
            "740/740 - 31s - loss: 0.0046 - mae: 0.0037 - val_loss: 0.0034 - val_mae: 0.0026\n",
            "Epoch 31/100\n",
            "740/740 - 31s - loss: 0.0047 - mae: 0.0038 - val_loss: 0.0055 - val_mae: 0.0046\n",
            "Epoch 32/100\n",
            "740/740 - 31s - loss: 0.0044 - mae: 0.0036 - val_loss: 0.0057 - val_mae: 0.0050\n",
            "Epoch 33/100\n",
            "740/740 - 31s - loss: 0.0044 - mae: 0.0036 - val_loss: 0.0040 - val_mae: 0.0033\n",
            "Epoch 34/100\n",
            "740/740 - 31s - loss: 0.0043 - mae: 0.0035 - val_loss: 0.0043 - val_mae: 0.0036\n",
            "Epoch 35/100\n",
            "740/740 - 31s - loss: 0.0043 - mae: 0.0035 - val_loss: 0.0048 - val_mae: 0.0039\n",
            "Epoch 36/100\n",
            "740/740 - 31s - loss: 0.0042 - mae: 0.0035 - val_loss: 0.0049 - val_mae: 0.0041\n",
            "Epoch 37/100\n",
            "740/740 - 31s - loss: 0.0043 - mae: 0.0035 - val_loss: 0.0043 - val_mae: 0.0035\n",
            "Epoch 38/100\n",
            "740/740 - 31s - loss: 0.0043 - mae: 0.0035 - val_loss: 0.0051 - val_mae: 0.0042\n",
            "Epoch 39/100\n",
            "740/740 - 31s - loss: 0.0040 - mae: 0.0033 - val_loss: 0.0044 - val_mae: 0.0036\n",
            "Epoch 40/100\n",
            "740/740 - 31s - loss: 0.0040 - mae: 0.0032 - val_loss: 0.0044 - val_mae: 0.0036\n",
            "Epoch 41/100\n",
            "740/740 - 32s - loss: 0.0040 - mae: 0.0032 - val_loss: 0.0045 - val_mae: 0.0035\n",
            "Epoch 42/100\n",
            "740/740 - 32s - loss: 0.0040 - mae: 0.0033 - val_loss: 0.0045 - val_mae: 0.0036\n",
            "Epoch 43/100\n",
            "740/740 - 32s - loss: 0.0040 - mae: 0.0032 - val_loss: 0.0039 - val_mae: 0.0032\n",
            "Epoch 44/100\n",
            "740/740 - 32s - loss: 0.0040 - mae: 0.0033 - val_loss: 0.0045 - val_mae: 0.0036\n",
            "Epoch 45/100\n",
            "740/740 - 31s - loss: 0.0038 - mae: 0.0031 - val_loss: 0.0058 - val_mae: 0.0048\n",
            "Epoch 46/100\n",
            "740/740 - 31s - loss: 0.0039 - mae: 0.0032 - val_loss: 0.0039 - val_mae: 0.0032\n",
            "Epoch 47/100\n",
            "740/740 - 31s - loss: 0.0038 - mae: 0.0031 - val_loss: 0.0042 - val_mae: 0.0033\n",
            "Epoch 48/100\n",
            "740/740 - 31s - loss: 0.0038 - mae: 0.0031 - val_loss: 0.0044 - val_mae: 0.0033\n",
            "Epoch 49/100\n",
            "740/740 - 31s - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0041 - val_mae: 0.0033\n",
            "Epoch 50/100\n",
            "740/740 - 31s - loss: 0.0043 - mae: 0.0035 - val_loss: 0.0066 - val_mae: 0.0057\n",
            "Epoch 51/100\n",
            "740/740 - 31s - loss: 0.0040 - mae: 0.0033 - val_loss: 0.0046 - val_mae: 0.0036\n",
            "Epoch 52/100\n",
            "740/740 - 31s - loss: 0.0039 - mae: 0.0031 - val_loss: 0.0037 - val_mae: 0.0030\n",
            "Epoch 53/100\n",
            "740/740 - 31s - loss: 0.0038 - mae: 0.0031 - val_loss: 0.0042 - val_mae: 0.0034\n",
            "Epoch 54/100\n",
            "740/740 - 31s - loss: 0.0038 - mae: 0.0031 - val_loss: 0.0041 - val_mae: 0.0031\n",
            "Epoch 55/100\n",
            "740/740 - 31s - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0038 - val_mae: 0.0030\n",
            "Epoch 56/100\n",
            "740/740 - 31s - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0030 - val_mae: 0.0024\n",
            "Epoch 57/100\n",
            "740/740 - 31s - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0044 - val_mae: 0.0036\n",
            "Epoch 58/100\n",
            "740/740 - 31s - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0037 - val_mae: 0.0031\n",
            "Epoch 59/100\n",
            "740/740 - 31s - loss: 0.0037 - mae: 0.0030 - val_loss: 0.0056 - val_mae: 0.0044\n",
            "Epoch 60/100\n",
            "740/740 - 31s - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0031 - val_mae: 0.0025\n",
            "Epoch 61/100\n",
            "740/740 - 31s - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0032 - val_mae: 0.0026\n",
            "Epoch 62/100\n",
            "740/740 - 31s - loss: 0.0035 - mae: 0.0029 - val_loss: 0.0045 - val_mae: 0.0034\n",
            "Epoch 63/100\n",
            "740/740 - 31s - loss: 0.0035 - mae: 0.0028 - val_loss: 0.0035 - val_mae: 0.0029\n",
            "Epoch 64/100\n",
            "740/740 - 31s - loss: 0.0034 - mae: 0.0027 - val_loss: 0.0041 - val_mae: 0.0034\n",
            "Epoch 65/100\n",
            "740/740 - 31s - loss: 0.0035 - mae: 0.0028 - val_loss: 0.0041 - val_mae: 0.0033\n",
            "Epoch 66/100\n",
            "740/740 - 31s - loss: 0.0034 - mae: 0.0027 - val_loss: 0.0033 - val_mae: 0.0027\n",
            "Epoch 67/100\n",
            "740/740 - 31s - loss: 0.0035 - mae: 0.0028 - val_loss: 0.0041 - val_mae: 0.0035\n",
            "Epoch 68/100\n",
            "740/740 - 31s - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0036 - val_mae: 0.0029\n",
            "Epoch 69/100\n",
            "740/740 - 31s - loss: 0.0034 - mae: 0.0027 - val_loss: 0.0037 - val_mae: 0.0030\n",
            "Epoch 70/100\n",
            "740/740 - 31s - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0034 - val_mae: 0.0027\n",
            "Epoch 71/100\n",
            "740/740 - 31s - loss: 0.0038 - mae: 0.0031 - val_loss: 0.0037 - val_mae: 0.0029\n",
            "Epoch 72/100\n",
            "740/740 - 31s - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0043 - val_mae: 0.0034\n",
            "Epoch 73/100\n",
            "740/740 - 31s - loss: 0.0034 - mae: 0.0027 - val_loss: 0.0043 - val_mae: 0.0035\n",
            "Epoch 74/100\n",
            "740/740 - 31s - loss: 0.0034 - mae: 0.0028 - val_loss: 0.0045 - val_mae: 0.0038\n",
            "Epoch 75/100\n",
            "740/740 - 31s - loss: 0.0033 - mae: 0.0027 - val_loss: 0.0039 - val_mae: 0.0029\n",
            "Epoch 76/100\n",
            "740/740 - 32s - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0040 - val_mae: 0.0033\n",
            "Epoch 77/100\n",
            "740/740 - 32s - loss: 0.0033 - mae: 0.0026 - val_loss: 0.0035 - val_mae: 0.0029\n",
            "Epoch 78/100\n",
            "740/740 - 32s - loss: 0.0034 - mae: 0.0028 - val_loss: 0.0037 - val_mae: 0.0030\n",
            "Epoch 79/100\n",
            "740/740 - 32s - loss: 0.0033 - mae: 0.0026 - val_loss: 0.0033 - val_mae: 0.0027\n",
            "Epoch 80/100\n",
            "740/740 - 31s - loss: 0.0033 - mae: 0.0027 - val_loss: 0.0039 - val_mae: 0.0033\n",
            "Epoch 81/100\n",
            "740/740 - 31s - loss: 0.0033 - mae: 0.0027 - val_loss: 0.0036 - val_mae: 0.0030\n",
            "Epoch 82/100\n",
            "740/740 - 32s - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0042 - val_mae: 0.0035\n",
            "Epoch 83/100\n",
            "740/740 - 32s - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0037 - val_mae: 0.0031\n",
            "Epoch 84/100\n",
            "740/740 - 31s - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0026 - val_mae: 0.0021\n",
            "Epoch 85/100\n",
            "740/740 - 32s - loss: 0.0030 - mae: 0.0024 - val_loss: 0.0037 - val_mae: 0.0030\n",
            "Epoch 86/100\n",
            "740/740 - 31s - loss: 0.0031 - mae: 0.0025 - val_loss: 0.0029 - val_mae: 0.0024\n",
            "Epoch 87/100\n",
            "740/740 - 31s - loss: 0.0030 - mae: 0.0025 - val_loss: 0.0041 - val_mae: 0.0032\n",
            "Epoch 88/100\n",
            "740/740 - 31s - loss: 0.0031 - mae: 0.0026 - val_loss: 0.0032 - val_mae: 0.0026\n",
            "Epoch 89/100\n",
            "740/740 - 31s - loss: 0.0031 - mae: 0.0025 - val_loss: 0.0034 - val_mae: 0.0027\n",
            "Epoch 90/100\n",
            "740/740 - 31s - loss: 0.0031 - mae: 0.0025 - val_loss: 0.0031 - val_mae: 0.0023\n",
            "Epoch 91/100\n",
            "740/740 - 31s - loss: 0.0031 - mae: 0.0025 - val_loss: 0.0037 - val_mae: 0.0029\n",
            "Epoch 92/100\n",
            "740/740 - 31s - loss: 0.0030 - mae: 0.0024 - val_loss: 0.0030 - val_mae: 0.0024\n",
            "Epoch 93/100\n",
            "740/740 - 31s - loss: 0.0031 - mae: 0.0026 - val_loss: 0.0027 - val_mae: 0.0022\n",
            "Epoch 94/100\n",
            "740/740 - 31s - loss: 0.0030 - mae: 0.0024 - val_loss: 0.0040 - val_mae: 0.0035\n",
            "Epoch 95/100\n",
            "740/740 - 31s - loss: 0.0031 - mae: 0.0025 - val_loss: 0.0031 - val_mae: 0.0025\n",
            "Epoch 96/100\n",
            "740/740 - 32s - loss: 0.0031 - mae: 0.0025 - val_loss: 0.0030 - val_mae: 0.0024\n",
            "Epoch 97/100\n",
            "740/740 - 31s - loss: 0.0043 - mae: 0.0035 - val_loss: 0.0047 - val_mae: 0.0037\n",
            "Epoch 98/100\n",
            "740/740 - 31s - loss: 0.0037 - mae: 0.0030 - val_loss: 0.0054 - val_mae: 0.0040\n",
            "Epoch 99/100\n",
            "740/740 - 31s - loss: 0.0037 - mae: 0.0030 - val_loss: 0.0059 - val_mae: 0.0044\n",
            "Epoch 100/100\n",
            "740/740 - 31s - loss: 0.0034 - mae: 0.0028 - val_loss: 0.0033 - val_mae: 0.0027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8ca21a8c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEipmYG7aL-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1ec2ccaa-d6f8-4e5b-bc3b-3da140240812"
      },
      "source": [
        "train_loss = model.history.history['loss']\n",
        "val_mae = model.history.history['val_mae']\n",
        "savez_compressed('train_loss.npz',train_loss)\n",
        "savez_compressed('val_mae.npz',val_mae)\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(range(n_epochs),train_loss,label=\"Train_LOSS\")\n",
        "plt.plot(range(n_epochs),val_mae,label=\"Val_MAE\")\n",
        "plt.legend()\n",
        "plt.title(\"Train-validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqwvSy6-aL-J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5d3fd63-2c5b-4369-f334-12496489dec6"
      },
      "source": [
        "plt.savefig(\"train-val_loss.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiQ48YF-aL-K"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\",\"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZumSpKcaL-K"
      },
      "source": [
        "model.save('LSTM_All.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBkygjSAaL-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f947b12-0db4-4a17-be17-ee886469f29c"
      },
      "source": [
        "# demonstrate prediction--test\n",
        "x_input = X_test_all\n",
        "print(x_input.shape)\n",
        "# reconstructed_model = keras.models.load_model('LSTM_All.h5')\n",
        "yhat_test = model.predict(x_input, verbose=0)\n",
        "savez_compressed('y_test_hat.npz',yhat_test)\n",
        "print(yhat_test.shape)\n",
        "\n",
        "# demonstrate prediction--val\n",
        "x_input = X_val_all\n",
        "print(x_input.shape)\n",
        "# reconstructed_model = keras.models.load_model('LSTM_All.h5')\n",
        "yhat_val = model.predict(x_input, verbose=0)\n",
        "savez_compressed('y_val_hat.npz',yhat_val)\n",
        "print(yhat_val.shape)\n",
        "\n",
        "# demonstrate prediction--train\n",
        "x_input = X_train_all\n",
        "print(x_input.shape)\n",
        "# reconstructed_model = keras.models.load_model('LSTM_All.h5')\n",
        "yhat_train = model.predict(x_input, verbose=0)\n",
        "savez_compressed('y_train_hat.npz',yhat_train)\n",
        "print(yhat_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4780, 30, 11)\n",
            "(4780, 1, 10)\n",
            "(9325, 30, 11)\n",
            "(9325, 1, 10)\n",
            "(23655, 30, 11)\n",
            "(23655, 1, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}